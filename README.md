# From Statistical Pattern Recognition to Emotion Analysis: The Decomposition Method in a Generating Element Space for NLP Models

This repository contains the source code and experiments for the research paper titled "From Statistical Pattern Recognition to Emotion Analysis: Applying the Decomposition Method in a Generating Element Space to NLP Models".

The study proposes and validates a novel hybrid approach for emotion detection in text. This method enhances modern transformer models by generating new "statistical-geometric" features based on the Kunchenko space decomposition method. These features capture the class-specific geometry of embedding spaces, acting as a powerful "refiner" for pre-trained models.

## Methodology Overview

The core idea is to supplement the outputs of transformer models (like RoBERTa or XLM-RoBERTa) with a new set of features. These features are generated by calculating the reconstruction error of a text's embedding using class-specific models.

1.  **Train Class-Specific Models:** For each emotion class, a unique Kunchenko reconstruction model is trained on embeddings belonging only to that class.
2.  **Generate Error Features:** For a new text, its embedding is passed through all trained reconstruction models. The reconstruction error from each model is calculated. A low error for a specific class model indicates that the embedding is "typical" for that class.
3.  **Create Hybrid Model:** The vector of reconstruction errors is concatenated with the original transformer's outputs (e.g., probabilities) and fed into a simple final classifier (like Logistic Regression or SVM).

## Repository Structure

The project is organized into several Python scripts, each corresponding to a specific experiment described in the paper.

### Ukrainian Dataset Experiments (EMOBENCH-UA)

*   `Base_test_emotions_hybrid_UA.py`:
    *   **Purpose:** Runs the main experiment comparing the baseline (thresholded probabilities) with the hybrid model.
    *   **Paper Reference:** **Table 1**.
    *   **Output:** Saves predictions and features to `experiment_outputs.npz` for further analysis.

*   `Analysis_base_test_result_UA.py`:
    *   **Purpose:** Performs post-analysis on the results from `Base_EMOBENCH-UA.py`. It runs an ablation study (Kunchenko features only) and a bootstrap test for statistical significance.
    *   **Paper Reference:** **Table 1** (Ablation result) and the p-value mentioned in **Section 3.1**.

*   `Basis_function_search_UA.py`:
    *   **Purpose:** Conducts a grid search to find the optimal basis function parameters (`n` and `alpha`) and compares Logistic Regression and SVM classifiers.
    *   **Paper Reference:** **Section 3.3.1**.

*   `Supervised_vs_unsupervised_UA.py`:
    *   **Purpose:** Compares the supervised Kunchenko feature space against the unsupervised PCA feature space. It also generates the t-SNE visualizations.
    *   **Paper Reference:** **Figure 1** and the related analysis.

### English Dataset Experiments (EmoEvent)

*   `Classic_vs_kunchenko_EN.py`:
    *   **Purpose:** Implements **Scenario A** (no model fine-tuning). Compares the classic TF-IDF + SVM baseline against Kunchenko features on "raw" RoBERTa embeddings.
    *   **Paper Reference:** **Section 3.2, Table 2**.

*   `Base_test_emotions_basis_search_EN.py`:
    *   **Purpose:** Implements **Scenario B** (with model fine-tuning). Fine-tunes a RoBERTa model and then performs a grid search for the optimal basis functions, comparing Logistic Regression and SVM.
    *   **Paper Reference:** **Section 3.3.2**. The results from this script are used to populate **Table 3**.


## How to Run the Experiments

### 1. Setup

Clone the repository and create a virtual environment.

```bash
git clone <repository-url>
cd <repository-name>
python -m venv venv
source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
```

### 2. Installation

Install the required dependencies from `requirements.txt`.

```bash
pip install -r requirements.txt
```
*(Note: A `requirements.txt` file should be created with the following key libraries: `torch`, `transformers`, `datasets`, `scikit-learn`, `pandas`, `matplotlib`, `seaborn`)*

### 3. Running the Scripts

The scripts can be run independently. They will automatically download the necessary models and datasets from the Hugging Face Hub and cache them locally.

**Example: To reproduce the main results for the Ukrainian dataset:**

1.  Run the main experiment to generate predictions:
    ```bash
    python Base_test_emotions_hybrid_UA.py
    ```
2.  Run the analysis script to get the ablation study and significance test:
    ```bash
    python Analysis_base_test_result_UA.py.py
    ```

The scripts will create output directories (e.g., `emo_event_search_results`, `comparison_results`) to store cached features and plots.

## Acknowledgment

This work is based on the theoretical foundations of statistical pattern recognition, particularly the decomposition method in a space with a generating element, developed by Prof. Yuriy P. Kunchenko.